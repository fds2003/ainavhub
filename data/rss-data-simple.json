{
  "articles": [
    {
      "title": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "title_zh": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "description": "By John P. Desmond, AI Trends Editor   Advancing trustworthy AI and machine learning to mitigate agency risk is a priority for the US Department of Energy (DOE), and identifying best practices for implementing AI at scale is a priority for the US General Services Administration (GSA).   That’s what attendees learned in two sessions at the AI [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/advance-trustworthy-ai-and-ml-and-identify-best-practices-for-scaling-ai/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study",
      "title_zh": "Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study",
      "description": "arXiv:2510.16095v1 Announce Type: new \nAbstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for explainable medical Artificial Intelligence (AI) while constrained by data scarcity. Although Large Language Models (LLMs) can synthesize medical data, their clinical reliability remains unverified. This study evaluates the reliability of LLM-generated CoTs and investigates prompting strategies to enhance their quality. In a blinded comparative study, senior clinicians in Assis",
      "link": "https://arxiv.org/abs/2510.16095",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "Best Practices for Building the AI Development Platform in Government",
      "title_zh": "Best Practices for Building the AI Development Platform in Government",
      "description": "By John P. Desmond, AI Trends Editor  The AI stack defined by Carnegie Mellon University is fundamental to the approach being taken by the US Army for its AI development platform efforts, according to Isaac Faber, Chief Data Scientist at the US Army AI Integration Center, speaking at the AI World Government event held in-person and virtually [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/best-practices-for-building-the-ai-development-platform-in-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "title_zh": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "description": "By John P. Desmond, AI Trends Editor    Two experiences of how AI developers within the federal government are pursuing AI accountability practices were outlined at the AI World Government event held virtually and in-person this week in Alexandria, Va.  Taka Ariga, chief data scientist and director at the US Government Accountability Office, described an AI accountability framework he uses within his agency [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/how-accountability-practices-are-pursued-by-ai-engineers-in-the-federal-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "title_zh": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "description": "By John P. Desmond, AI Trends Editor   Engineers tend to see things in unambiguous terms, which some may call Black and White terms, such as a choice between right or wrong and good and bad. The consideration of ethics in AI is highly nuanced, with vast gray areas, making it  challenging for AI software engineers to [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/getting-government-ai-engineers-to-tune-into-ai-ethics-seen-as-challenge/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "title_zh": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "description": "By Lance Eliot, the AI Trends Insider   We already expect that humans to exhibit flashes of brilliance. It might not happen all the time, but the act itself is welcomed and not altogether disturbing when it occurs.    What about when Artificial Intelligence (AI) seems to display an act of novelty? Any such instance is bound to get our attention; [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-insider/novelty-in-the-game-of-go-provides-bright-insights-for-ai-and-autonomous-vehicles/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "title_zh": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "description": "By AI Trends Staff   While AI in hiring is now widely used for writing job descriptions, screening candidates, and automating interviews, it poses a risk of wide discrimination if not implemented carefully.  That was the message from Keith Sonderling, Commissioner with the US Equal Opportunity Commision, speaking at the AI World Government event held live and virtually in [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/promise-and-perils-of-using-ai-for-hiring-guard-against-data-bias/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "title_zh": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "description": "By John P. Desmond, AI Trends Editor   More companies are successfully exploiting predictive maintenance systems that combine AI and IoT sensors to collect data that anticipates breakdowns and recommends preventive action before break or machines fail, in a demonstration of an AI use case with proven value.   This growth is reflected in optimistic market forecasts. [&#8230;]]]>",
      "link": "https://www.aitrends.com/predictive-analytics/predictive-maintenance-proving-out-as-successful-ai-use-case/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "title_zh": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "description": "By John P. Desmond, AI Trends Editor   AI is more accessible to young people in the workforce who grew up as ‘digital natives’ with Alexa and self-driving cars as part of the landscape, giving them expectations grounded in their experience of what is possible.   That idea set the foundation for a panel discussion at AI World [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/digital-natives-seen-having-advantages-as-part-of-government-ai-engineering-teams/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding",
      "title_zh": "Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding",
      "description": "arXiv:2510.15952v1 Announce Type: new \nAbstract: Large language models exhibit intelligence without genuine epistemic understanding, exposing a key gap: the absence of epistemic architecture. This paper introduces the Structured Cognitive Loop (SCL) as an executable epistemological framework for emergent intelligence. Unlike traditional AI research asking \"what is intelligence?\" (ontological), SCL asks \"under what conditions does cognition emerge?\" (epistemological). Grounded in philosophy of mi",
      "link": "https://arxiv.org/abs/2510.15952",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency",
      "title_zh": "PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency",
      "description": "arXiv:2510.15966v1 Announce Type: new \nAbstract: Memory systems are fundamental to AI agents, yet existing work often lacks adaptability to diverse tasks and overlooks the constructive and task-oriented role of AI agent memory. Drawing from Piaget's theory of cognitive development, we propose PISA, a pragmatic, psych-inspired unified memory system that addresses these limitations by treating memory as a constructive and adaptive process. To enable continuous learning and adaptability, PISA intro",
      "link": "https://arxiv.org/abs/2510.15966",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI",
      "title_zh": "The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI",
      "description": "arXiv:2510.16206v1 Announce Type: new \nAbstract: Since the rapid expansion of large language models (LLMs), people have begun to rely on them for information retrieval. While traditional search engines display ranked lists of sources shaped by search engine optimization (SEO), advertising, and personalization, LLMs typically provide a synthesized response that feels singular and authoritative. While both approaches carry risks of bias and omission, LLMs may amplify the effect by collapsing multi",
      "link": "https://arxiv.org/abs/2510.16206",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration",
      "title_zh": "Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration",
      "description": "arXiv:2510.16194v1 Announce Type: new \nAbstract: Protected health information (PHI) de-identification is critical for enabling the safe reuse of clinical notes, yet evaluating and comparing PHI de-identification models typically depends on costly, small-scale expert annotations. We present TEAM-PHI, a multi-agent evaluation and selection framework that uses large language models (LLMs) to automatically measure de-identification quality and select the best-performing model without heavy reliance ",
      "link": "https://arxiv.org/abs/2510.16194",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability",
      "title_zh": "Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability",
      "description": "arXiv:2510.16193v1 Announce Type: new \nAbstract: Corporate responsibility turns on notions of corporate \\textit{mens rea}, traditionally imputed from human agents. Yet these assumptions are under challenge as generative AI increasingly mediates enterprise decision-making. Building on the theory of extended cognition, we argue that in response corporate knowledge may be redefined as a dynamic capability, measurable by the efficiency of its information-access procedures and the validated reliabili",
      "link": "https://arxiv.org/abs/2510.16193",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games",
      "title_zh": "Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games",
      "description": "arXiv:2510.15974v1 Announce Type: new \nAbstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in performance on solving puzzles beyond certain perplexity thresholds. In subsequent discourse, questions have arisen as to whether the nature of the task muddles an evaluation of true reasoning. One potential confound is the requirement that the model keep track of the state space on its own. We provide a large language model (LLM) with an environment interface for Tower o",
      "link": "https://arxiv.org/abs/2510.15974",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    },
    {
      "title": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction",
      "title_zh": "PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction",
      "description": "arXiv:2510.16004v1 Announce Type: new \nAbstract: Neural surrogates have shown great potential in simulating dynamical systems, while offering real-time capabilities. We envision Neural Twins as a progression of neural surrogates, aiming to create digital replicas of real systems. A neural twin consumes measurements at test time to update its state, thereby enabling context-specific decision-making. A critical property of neural twins is their ability to remain on-trajectory, i.e., to stay close ",
      "link": "https://arxiv.org/abs/2510.16004",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-10-21"
    }
  ]
}