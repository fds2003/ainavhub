{
  "articles": [
    {
      "title": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act",
      "title_zh": "Integrating Generative AI-enhanced Cognitive Systems in Higher Education: From Stakeholder Perceptions to a Conceptual Framework considering the EU AI Act",
      "description": "arXiv:2602.10802v1 Announce Type: new \nAbstract: Many staff and students in higher education have adopted generative artificial intelligence (GenAI) tools in their work and study. GenAI is expected to enhance cognitive systems by enabling personalized learning and streamlining educational services. However, stakeholders perceptions of GenAI in higher education remain divided, shaped by cultural, disciplinary, and institutional contexts. In addition, the EU AI Act requires universities to ensure ",
      "link": "https://arxiv.org/abs/2602.10802",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
      "title_zh": "Discovering Differences in Strategic Behavior Between Humans and LLMs",
      "description": "arXiv:2602.10324v1 Announce Type: new \nAbstract: As Large Language Models (LLMs) are increasingly deployed in social and strategic scenarios, it becomes critical to understand where and why their behavior diverges from that of humans. While behavioral game theory (BGT) provides a framework for analyzing behavior, existing models do not fully capture the idiosyncratic behavior of humans or black-box, non-human agents like LLMs. We employ AlphaEvolve, a cutting-edge program discovery tool, to dire",
      "link": "https://arxiv.org/abs/2602.10324",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
      "title_zh": "LiveMedBench: A Contamination-Free Medical Benchmark for LLMs with Automated Rubric Evaluation",
      "description": "arXiv:2602.10367v1 Announce Type: new \nAbstract: The deployment of Large Language Models (LLMs) in high-stakes clinical settings demands rigorous and reliable evaluation. However, existing medical benchmarks remain static, suffering from two critical limitations: (1) data contamination, where test sets inadvertently leak into training corpora, leading to inflated performance estimates; and (2) temporal misalignment, failing to capture the rapid evolution of medical knowledge. Furthermore, curren",
      "link": "https://arxiv.org/abs/2602.10367",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators",
      "title_zh": "MERIT Feedback Elicits Better Bargaining in LLM Negotiators",
      "description": "arXiv:2602.10467v1 Announce Type: new \nAbstract: Bargaining is often regarded as a logical arena rather than an art or a matter of intuition, yet Large Language Models (LLMs) still struggle to navigate it due to limited strategic depth and difficulty adapting to complex human factors. Current benchmarks rarely capture this limitation. To bridge this gap, we present an utility feedback centric framework. Our contributions are: (i) AgoraBench, a new benchmark spanning nine challenging settings (e.",
      "link": "https://arxiv.org/abs/2602.10467",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
      "title_zh": "Found-RL: foundation model-enhanced reinforcement learning for autonomous driving",
      "description": "arXiv:2602.10458v1 Announce Type: new \nAbstract: Reinforcement Learning (RL) has emerged as a dominant paradigm for end-to-end autonomous driving (AD). However, RL suffers from sample inefficiency and a lack of semantic interpretability in complex scenarios. Foundation Models, particularly Vision-Language Models (VLMs), can mitigate this by offering rich, context-aware knowledge, yet their high inference latency hinders deployment in high-frequency RL training loops. To bridge this gap, we prese",
      "link": "https://arxiv.org/abs/2602.10458",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
      "title_zh": "Neuro-symbolic Action Masking for Deep Reinforcement Learning",
      "description": "arXiv:2602.10598v1 Announce Type: new \nAbstract: Deep reinforcement learning (DRL) may explore infeasible actions during training and execution. Existing approaches assume a symbol grounding function that maps high-dimensional states to consistent symbolic representations and a manually specified action masking techniques to constrain actions. In this paper, we propose Neuro-symbolic Action Masking (NSAM), a novel framework that automatically learn symbolic models, which are consistent with give",
      "link": "https://arxiv.org/abs/2602.10598",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization",
      "title_zh": "OmniSapiens: A Foundation Model for Social Behavior Processing via Heterogeneity-Aware Relative Policy Optimization",
      "description": "arXiv:2602.10635v1 Announce Type: new \nAbstract: To develop socially intelligent AI, existing approaches typically model human behavioral dimensions (e.g., affective, cognitive, or social attributes) in isolation. Although useful, task-specific modeling often increases training costs and limits generalization across behavioral settings. Recent reasoning RL methods facilitate training a single unified model across multiple behavioral tasks, but do not explicitly address learning across different ",
      "link": "https://arxiv.org/abs/2602.10635",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    },
    {
      "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
      "title_zh": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
      "description": "arXiv:2602.10814v1 Announce Type: new \nAbstract: Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanni",
      "link": "https://arxiv.org/abs/2602.10814",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2026-02-12"
    }
  ]
}