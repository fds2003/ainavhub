{
  "articles": [
    {
      "title": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "title_zh": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "description": "By John P. Desmond, AI Trends Editor   Advancing trustworthy AI and machine learning to mitigate agency risk is a priority for the US Department of Energy (DOE), and identifying best practices for implementing AI at scale is a priority for the US General Services Administration (GSA).   That’s what attendees learned in two sessions at the AI [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/advance-trustworthy-ai-and-ml-and-identify-best-practices-for-scaling-ai/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "A Rosetta Stone for AI Benchmarks",
      "title_zh": "A Rosetta Stone for AI Benchmarks",
      "description": "arXiv:2512.00193v1 Announce Type: new \nAbstract: Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a \"Rosetta Stone\", allowing us to compare models across a wide range of abilities and time, even if they are not eval",
      "link": "https://arxiv.org/abs/2512.00193",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "Best Practices for Building the AI Development Platform in Government",
      "title_zh": "Best Practices for Building the AI Development Platform in Government",
      "description": "By John P. Desmond, AI Trends Editor  The AI stack defined by Carnegie Mellon University is fundamental to the approach being taken by the US Army for its AI development platform efforts, according to Isaac Faber, Chief Data Scientist at the US Army AI Integration Center, speaking at the AI World Government event held in-person and virtually [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/best-practices-for-building-the-ai-development-platform-in-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "title_zh": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "description": "By John P. Desmond, AI Trends Editor    Two experiences of how AI developers within the federal government are pursuing AI accountability practices were outlined at the AI World Government event held virtually and in-person this week in Alexandria, Va.  Taka Ariga, chief data scientist and director at the US Government Accountability Office, described an AI accountability framework he uses within his agency [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/how-accountability-practices-are-pursued-by-ai-engineers-in-the-federal-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "title_zh": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "description": "By John P. Desmond, AI Trends Editor   Engineers tend to see things in unambiguous terms, which some may call Black and White terms, such as a choice between right or wrong and good and bad. The consideration of ethics in AI is highly nuanced, with vast gray areas, making it  challenging for AI software engineers to [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/getting-government-ai-engineers-to-tune-into-ai-ethics-seen-as-challenge/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "title_zh": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "description": "By Lance Eliot, the AI Trends Insider   We already expect that humans to exhibit flashes of brilliance. It might not happen all the time, but the act itself is welcomed and not altogether disturbing when it occurs.    What about when Artificial Intelligence (AI) seems to display an act of novelty? Any such instance is bound to get our attention; [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-insider/novelty-in-the-game-of-go-provides-bright-insights-for-ai-and-autonomous-vehicles/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "title_zh": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "description": "By AI Trends Staff   While AI in hiring is now widely used for writing job descriptions, screening candidates, and automating interviews, it poses a risk of wide discrimination if not implemented carefully.  That was the message from Keith Sonderling, Commissioner with the US Equal Opportunity Commision, speaking at the AI World Government event held live and virtually in [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/promise-and-perils-of-using-ai-for-hiring-guard-against-data-bias/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "title_zh": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "description": "By John P. Desmond, AI Trends Editor   More companies are successfully exploiting predictive maintenance systems that combine AI and IoT sensors to collect data that anticipates breakdowns and recommends preventive action before break or machines fail, in a demonstration of an AI use case with proven value.   This growth is reflected in optimistic market forecasts. [&#8230;]]]>",
      "link": "https://www.aitrends.com/predictive-analytics/predictive-maintenance-proving-out-as-successful-ai-use-case/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "title_zh": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "description": "By John P. Desmond, AI Trends Editor   AI is more accessible to young people in the workforce who grew up as ‘digital natives’ with Alexa and self-driving cars as part of the landscape, giving them expectations grounded in their experience of what is possible.   That idea set the foundation for a panel discussion at AI World [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/digital-natives-seen-having-advantages-as-part-of-government-ai-engineering-teams/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Gold-Medal-Level Olympiad Geometry Solving with Efficient Heuristic Auxiliary Constructions",
      "title_zh": "Gold-Medal-Level Olympiad Geometry Solving with Efficient Heuristic Auxiliary Constructions",
      "description": "arXiv:2512.00097v1 Announce Type: new \nAbstract: Automated theorem proving in Euclidean geometry, particularly for International Mathematical Olympiad (IMO) level problems, remains a major challenge and an important research focus in Artificial Intelligence. In this paper, we present a highly efficient method for geometry theorem proving that runs entirely on CPUs without relying on neural network-based inference. Our initial study shows that a simple random strategy for adding auxiliary points ",
      "link": "https://arxiv.org/abs/2512.00097",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "Chunking Strategies for Multimodal AI Systems",
      "title_zh": "Chunking Strategies for Multimodal AI Systems",
      "description": "arXiv:2512.00185v1 Announce Type: new \nAbstract: Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a co",
      "link": "https://arxiv.org/abs/2512.00185",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs",
      "title_zh": "RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs",
      "description": "arXiv:2512.00319v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language generation and reasoning. However, their integration into automated software ecosystems is often hindered by the \"Structure Gap\" - the inherent tension between the probabilistic nature of token generation and the deterministic requirements of structured data formats (e.g., JSON, XML). Traditional Supervised Fine-Tuning (SFT) often fails to enforce strict syn",
      "link": "https://arxiv.org/abs/2512.00319",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System",
      "title_zh": "CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System",
      "description": "arXiv:2512.00331v1 Announce Type: new \nAbstract: Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended",
      "link": "https://arxiv.org/abs/2512.00331",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?",
      "title_zh": "Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?",
      "description": "arXiv:2512.00218v1 Announce Type: new \nAbstract: AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \\emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \\emph{trai",
      "link": "https://arxiv.org/abs/2512.00218",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking",
      "title_zh": "Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking",
      "description": "arXiv:2512.00267v1 Announce Type: new \nAbstract: Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two l",
      "link": "https://arxiv.org/abs/2512.00267",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    },
    {
      "title": "Echo-N1: Affective RL Frontier",
      "title_zh": "Echo-N1: Affective RL Frontier",
      "description": "arXiv:2512.00344v1 Announce Type: new \nAbstract: The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not onl",
      "link": "https://arxiv.org/abs/2512.00344",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-02"
    }
  ]
}