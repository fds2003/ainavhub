{
  "articles": [
    {
      "title": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "title_zh": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "description": "By John P. Desmond, AI Trends Editor   Advancing trustworthy AI and machine learning to mitigate agency risk is a priority for the US Department of Energy (DOE), and identifying best practices for implementing AI at scale is a priority for the US General Services Administration (GSA).   That’s what attendees learned in two sessions at the AI [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/advance-trustworthy-ai-and-ml-and-identify-best-practices-for-scaling-ai/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Best Practices for Building the AI Development Platform in Government",
      "title_zh": "Best Practices for Building the AI Development Platform in Government",
      "description": "By John P. Desmond, AI Trends Editor  The AI stack defined by Carnegie Mellon University is fundamental to the approach being taken by the US Army for its AI development platform efforts, according to Isaac Faber, Chief Data Scientist at the US Army AI Integration Center, speaking at the AI World Government event held in-person and virtually [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/best-practices-for-building-the-ai-development-platform-in-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "title_zh": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "description": "By John P. Desmond, AI Trends Editor    Two experiences of how AI developers within the federal government are pursuing AI accountability practices were outlined at the AI World Government event held virtually and in-person this week in Alexandria, Va.  Taka Ariga, chief data scientist and director at the US Government Accountability Office, described an AI accountability framework he uses within his agency [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/how-accountability-practices-are-pursued-by-ai-engineers-in-the-federal-government/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases",
      "title_zh": "Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases",
      "description": "arXiv:2512.04287v1 Announce Type: new \nAbstract: This review explores the integration of Artificial Intelligence into Horizon Scanning, focusing on identifying and responding to emerging threats and opportunities linked to Infectious Diseases. We examine how AI tools can enhance signal detection, data monitoring, scenario analysis, and decision support. We also address the risks associated with AI adoption and propose strategies for effective implementation and governance. The findings contribut",
      "link": "https://arxiv.org/abs/2512.04287",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "title_zh": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "description": "By John P. Desmond, AI Trends Editor   Engineers tend to see things in unambiguous terms, which some may call Black and White terms, such as a choice between right or wrong and good and bad. The consideration of ethics in AI is highly nuanced, with vast gray areas, making it  challenging for AI software engineers to [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/getting-government-ai-engineers-to-tune-into-ai-ethics-seen-as-challenge/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "The Geometry of Benchmarks: A New Path Toward AGI",
      "title_zh": "The Geometry of Benchmarks: A New Path Toward AGI",
      "description": "arXiv:2512.04276v1 Announce Type: new \nAbstract: Benchmarks are the primary tool for assessing progress in artificial intelligence (AI), yet current practice evaluates models on isolated test suites and provides little guidance for reasoning about generality or autonomous self-improvement. Here we introduce a geometric framework in which all psychometric batteries for AI agents are treated as points in a structured moduli space, and agent performance is described by capability functionals over t",
      "link": "https://arxiv.org/abs/2512.04276",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "title_zh": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "description": "By Lance Eliot, the AI Trends Insider   We already expect that humans to exhibit flashes of brilliance. It might not happen all the time, but the act itself is welcomed and not altogether disturbing when it occurs.    What about when Artificial Intelligence (AI) seems to display an act of novelty? Any such instance is bound to get our attention; [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-insider/novelty-in-the-game-of-go-provides-bright-insights-for-ai-and-autonomous-vehicles/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "title_zh": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "description": "By AI Trends Staff   While AI in hiring is now widely used for writing job descriptions, screening candidates, and automating interviews, it poses a risk of wide discrimination if not implemented carefully.  That was the message from Keith Sonderling, Commissioner with the US Equal Opportunity Commision, speaking at the AI World Government event held live and virtually in [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/promise-and-perils-of-using-ai-for-hiring-guard-against-data-bias/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "title_zh": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "description": "By John P. Desmond, AI Trends Editor   More companies are successfully exploiting predictive maintenance systems that combine AI and IoT sensors to collect data that anticipates breakdowns and recommends preventive action before break or machines fail, in a demonstration of an AI use case with proven value.   This growth is reflected in optimistic market forecasts. [&#8230;]]]>",
      "link": "https://www.aitrends.com/predictive-analytics/predictive-maintenance-proving-out-as-successful-ai-use-case/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-28"
    },
    {
      "title": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "title_zh": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "description": "By John P. Desmond, AI Trends Editor   AI is more accessible to young people in the workforce who grew up as ‘digital natives’ with Alexa and self-driving cars as part of the landscape, giving them expectations grounded in their experience of what is possible.   That idea set the foundation for a panel discussion at AI World [&#8230;]]]>",
      "link": "https://www.aitrends.com/ai-world-government/digital-natives-seen-having-advantages-as-part-of-government-ai-engineering-teams/",
      "source": "AI 趋势",
      "category": "行业趋势",
      "date": "2021-10-21"
    },
    {
      "title": "Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care",
      "title_zh": "Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care",
      "description": "arXiv:2512.04207v1 Announce Type: new \nAbstract: Unlike most primary headaches, secondary headaches need specialized care and can have devastating consequences if not treated promptly. Clinical guidelines highlight several 'red flag' features, such as thunderclap onset, meningismus, papilledema, focal neurologic deficits, signs of temporal arteritis, systemic illness, and the 'worst headache of their life' presentation. Despite these guidelines, determining which patients require urgent evaluati",
      "link": "https://arxiv.org/abs/2512.04207",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Solving N-Queen Problem using Las Vegas Algorithm with State Pruning",
      "title_zh": "Solving N-Queen Problem using Las Vegas Algorithm with State Pruning",
      "description": "arXiv:2512.04139v1 Announce Type: new \nAbstract: The N-Queens problem, placing all N queens in a N x N chessboard where none attack the other, is a classic problem for constraint satisfaction algorithms. While complete methods like backtracking guarantee a solution, their exponential time complexity makes them impractical for large-scale instances thus, stochastic approaches, such as Las Vegas algorithm, are preferred. While it offers faster approximate solutions, it suffers from significant per",
      "link": "https://arxiv.org/abs/2512.04139",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Towards better dense rewards in Reinforcement Learning Applications",
      "title_zh": "Towards better dense rewards in Reinforcement Learning Applications",
      "description": "arXiv:2512.04302v1 Announce Type: new \nAbstract: Finding meaningful and accurate dense rewards is a fundamental task in the field of reinforcement learning (RL) that enables agents to explore environments more efficiently. In traditional RL settings, agents learn optimal policies through interactions with an environment guided by reward signals. However, when these signals are sparse, delayed, or poorly aligned with the intended task objectives, agents often struggle to learn effectively. Dense ",
      "link": "https://arxiv.org/abs/2512.04302",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment",
      "title_zh": "Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment",
      "description": "arXiv:2512.04210v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly used in healthcare, yet ensuring their safety and trustworthiness remains a barrier to deployment. Conversational medical assistants must avoid unsafe compliance without over-refusing benign queries. We present an iterative post-deployment alignment framework that applies Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to refine models against domain-specific safety signals",
      "link": "https://arxiv.org/abs/2512.04210",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Toward Virtuous Reinforcement Learning",
      "title_zh": "Toward Virtuous Reinforcement Learning",
      "description": "arXiv:2512.04246v1 Announce Type: new \nAbstract: This paper critiques common patterns in machine ethics for Reinforcement Learning (RL) and argues for a virtue focused alternative. We highlight two recurring limitations in much of the current literature: (i) rule based (deontological) methods that encode duties as constraints or shields often struggle under ambiguity and nonstationarity and do not cultivate lasting habits, and (ii) many reward based approaches, especially single objective RL, im",
      "link": "https://arxiv.org/abs/2512.04246",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    },
    {
      "title": "Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework",
      "title_zh": "Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework",
      "description": "arXiv:2512.04228v1 Announce Type: new \nAbstract: Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \\textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manip",
      "link": "https://arxiv.org/abs/2512.04228",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "date": "2025-12-05"
    }
  ]
}