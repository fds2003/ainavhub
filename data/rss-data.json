{
  "articles": [
    {
      "title": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach",
      "link": "https://arxiv.org/abs/2512.13714",
      "description": "arXiv:2512.13714v1 Announce Type: new \nAbstract: LLM implementations are failing in highly regulated industries owing to instability issues, inconsistent reasoning, hallucinations and performance variability, especially in workflows. These reliability issues restrict safe use of LLM in areas that need the precision of facts and consistent behavior (Aiyappa et al., 2023). The current methods of stabilization, such as, reinforcement learning with human feedback (RLHF) and supervised fine-tuning, o",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 27,
      "title_zh": "AI-Powered Annotation Pipelines for Stabilizing Large Language Models: A Human-AI Synergy Approach"
    },
    {
      "title": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making",
      "link": "https://arxiv.org/abs/2512.13716",
      "description": "arXiv:2512.13716v1 Announce Type: new \nAbstract: Personalized decision-making is essential for human-AI interaction, enabling AI agents to act in alignment with individual users' value preferences. As AI systems expand into real-world applications, adapting to personalized values beyond task completion or collective alignment has become a critical challenge. We address this by proposing a value-driven approach to personalized decision-making. Human values serve as stable, transferable signals th",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 25,
      "title_zh": "ValuePilot: A Two-Phase Framework for Value-Driven Decision-Making"
    },
    {
      "title": "Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN",
      "link": "https://arxiv.org/abs/2512.13715",
      "description": "arXiv:2512.13715v1 Announce Type: new \nAbstract: The increasing complexity of modern applications demands wireless networks capable of real time adaptability and efficient resource management. The Open Radio Access Network (O-RAN) architecture, with its RAN Intelligent Controller (RIC) modules, has emerged as a pivotal solution for dynamic resource management and network slicing. While artificial intelligence (AI) driven methods have shown promise, most approaches struggle to maintain performanc",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 13,
      "title_zh": "Meta Hierarchical Reinforcement Learning for Scalable Resource Management in O-RAN"
    },
    {
      "title": "Mathematics and Coding are Universal AI Benchmarks",
      "link": "https://arxiv.org/abs/2512.13764",
      "description": "arXiv:2512.13764v1 Announce Type: new \nAbstract: We study the special role of mathematics and coding inside the moduli space of psychometric batteries for AI agents. Building on the AAI framework and GVU dynamics from previous works, we define the Mathematics Fiber and show that, when paired with formal proof kernels (e.g. Lean, Coq), GVU flows on this fiber admit spectrally stable self-improvement regimes due to oracle-like verification. Our main technical result is a density theorem: under uni",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 12,
      "title_zh": "Mathematics and Coding are Universal AI Benchmarks"
    },
    {
      "title": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents",
      "link": "https://arxiv.org/abs/2512.13704",
      "description": "arXiv:2512.13704v1 Announce Type: new \nAbstract: The performance of production machine learning systems is fundamentally limited by the quality of their training data. In high-stakes industrial applications, noisy labels can degrade performance and erode user trust. This paper presents Adjudicator, a system that addresses the critical data mining challenge of automatically identifying and correcting label noise and has been validated for production deployment. Adjudicator models this as a neuro-",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 10,
      "title_zh": "Adjudicator: Correcting Noisy Labels with a KG-Informed Council of LLM Agents"
    },
    {
      "title": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms",
      "link": "https://arxiv.org/abs/2512.13713",
      "description": "arXiv:2512.13713v1 Announce Type: new \nAbstract: Large Language Models (LLMs) are increasingly being utilized as autonomous agents, yet their ability to coordinate in distributed systems remains poorly understood. We introduce \\textbf{LoopBench}, a benchmark to evaluate LLM reasoning in distributed symmetry breaking and meta-cognitive thinking. The benchmark focuses on coloring odd cycle graphs ($C_3, C_5, C_{11}$) with limited colors, where deterministic, non-communicating agents fail in infini",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 6,
      "title_zh": "LoopBench: Discovering Emergent Symmetry Breaking Strategies with LLM Swarms"
    },
    {
      "title": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy",
      "link": "https://arxiv.org/abs/2512.13725",
      "description": "arXiv:2512.13725v1 Announce Type: new \nAbstract: Causal reasoning in Large Language Models spanning association, intervention, and counterfactual inference is essential for reliable decision making in high stakes settings. As deployment shifts toward edge and resource constrained environments, quantized models such as INT8 and NF4 are becoming standard. Yet the impact of precision reduction on formal causal reasoning is poorly understood. To our knowledge, this is the first study to systematical",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 4,
      "title_zh": "Compressed Causal Reasoning: Quantization and GraphRAG Effects on Interventional and Counterfactual Accuracy"
    },
    {
      "title": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records",
      "link": "https://arxiv.org/abs/2512.13700",
      "description": "arXiv:2512.13700v1 Announce Type: new \nAbstract: Manual chart review remains an extremely time-consuming and resource-intensive component of clinical research, requiring experts to extract often complex information from unstructured electronic health record (EHR) narratives. We present a secure, modular framework for automated structured feature extraction from clinical notes leveraging locally deployed large language models (LLMs) on institutionally approved, Health Insurance Portability and Ac",
      "pubDate": "2025-12-18T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 3,
      "title_zh": "Leveraging LLMs for Structured Data Extraction from Unstructured Patient Records"
    }
  ],
  "metadata": {
    "totalCount": 8,
    "generatedAt": "2025-12-18T09:16:24.983Z",
    "sources": [
      {
        "name": "ArXiv AI 研究",
        "category": "学术研究",
        "weight": 0.9
      },
      {
        "name": "MIT人工智能新闻",
        "category": "学术动态",
        "weight": 0.85
      },
      {
        "name": "AI 趋势",
        "category": "行业趋势",
        "weight": 0.8
      },
      {
        "name": "VentureBeat AI",
        "category": "商业资讯",
        "weight": 0.8
      }
    ],
    "keywords": {
      "tier1": {
        "artificial intelligence": 5,
        "AI": 4,
        "machine learning": 4,
        "deep learning": 4,
        "neural network": 3,
        "neural networks": 3,
        "LLM": 3,
        "GPT": 3,
        "ChatGPT": 3,
        "computer vision": 3,
        "natural language processing": 3,
        "NLP": 3,
        "robotics": 2.5,
        "automation": 2.5,
        "algorithm": 2
      },
      "tier2": {
        "transformer": 2,
        "bert": 2,
        "dall-e": 2,
        "stable diffusion": 2,
        "reinforcement learning": 2,
        "supervised learning": 2,
        "unsupervised learning": 2,
        "data science": 1.5,
        "big data": 1.5,
        "cloud computing": 1,
        "edge computing": 1
      }
    }
  },
  "summary": {
    "researchArticles": 8,
    "industryArticles": 0,
    "academicArticles": 8,
    "averageScore": 12.5
  }
}