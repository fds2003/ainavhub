{
  "articles": [
    {
      "title": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI",
      "link": "https://www.aitrends.com/ai-world-government/advance-trustworthy-ai-and-ml-and-identify-best-practices-for-scaling-ai/",
      "description": "By John P. Desmond, AI Trends Editor   Advancing trustworthy AI and machine learning to mitigate agency risk is a priority for the US Department of Energy (DOE), and identifying best practices for implementing AI at scale is a priority for the US General Services Administration (GSA).   That’s what attendees learned in two sessions at the AI [&#8230;]]]>",
      "pubDate": "2021-10-28T23:19:58.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 28,
      "title_zh": "Advance Trustworthy AI and ML, and Identify Best Practices for Scaling AI"
    },
    {
      "title": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective",
      "link": "https://arxiv.org/abs/2602.07259",
      "description": "arXiv:2602.07259v1 Announce Type: new \nAbstract: As AI systems grow more capable and autonomous, ensuring their safety and reliability requires not only model-level alignment but also strategic oversight of the humans and institutions involved in their development and deployment. Existing safety frameworks largely treat alignment as a static optimization problem (e.g., tuning models to desired behavior) while overlooking the dynamic, adversarial incentives that shape how data are collected, how ",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 24,
      "title_zh": "Incentive-Aware AI Safety via Strategic Resource Allocation: A Stackelberg Security Games Perspective"
    },
    {
      "title": "Best Practices for Building the AI Development Platform in Government",
      "link": "https://www.aitrends.com/ai-world-government/best-practices-for-building-the-ai-development-platform-in-government/",
      "description": "By John P. Desmond, AI Trends Editor  The AI stack defined by Carnegie Mellon University is fundamental to the approach being taken by the US Army for its AI development platform efforts, according to Isaac Faber, Chief Data Scientist at the US Army AI Integration Center, speaking at the AI World Government event held in-person and virtually [&#8230;]]]>",
      "pubDate": "2021-10-28T23:20:17.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 24,
      "title_zh": "Best Practices for Building the AI Development Platform in Government"
    },
    {
      "title": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government",
      "link": "https://www.aitrends.com/ai-world-government/how-accountability-practices-are-pursued-by-ai-engineers-in-the-federal-government/",
      "description": "By John P. Desmond, AI Trends Editor    Two experiences of how AI developers within the federal government are pursuing AI accountability practices were outlined at the AI World Government event held virtually and in-person this week in Alexandria, Va.  Taka Ariga, chief data scientist and director at the US Government Accountability Office, described an AI accountability framework he uses within his agency [&#8230;]]]>",
      "pubDate": "2021-10-21T20:34:39.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 24,
      "title_zh": "How Accountability Practices Are Pursued by AI Engineers in the Federal Government"
    },
    {
      "title": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge",
      "link": "https://www.aitrends.com/ai-world-government/getting-government-ai-engineers-to-tune-into-ai-ethics-seen-as-challenge/",
      "description": "By John P. Desmond, AI Trends Editor   Engineers tend to see things in unambiguous terms, which some may call Black and White terms, such as a choice between right or wrong and good and bad. The consideration of ethics in AI is highly nuanced, with vast gray areas, making it  challenging for AI software engineers to [&#8230;]]]>",
      "pubDate": "2021-10-21T21:02:24.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 20,
      "title_zh": "Getting Government AI Engineers to Tune into AI Ethics Seen as Challenge"
    },
    {
      "title": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation",
      "link": "https://arxiv.org/abs/2602.07032",
      "description": "arXiv:2602.07032v1 Announce Type: new \nAbstract: Finite-state reasoning, the ability to understand and implement state-dependent behavior, is central to hardware design. In this paper, we present LLM-FSM, a benchmark that evaluates how well large language models (LLMs) can recover finite-state machine (FSM) behavior from natural-language specifications and translate it into correct register transfer-level (RTL) implementations. Unlike prior specification-to-RTL benchmarks that rely on manually c",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 18,
      "title_zh": "LLM-FSM: Scaling Large Language Models for Finite-State Reasoning in RTL Code Generation"
    },
    {
      "title": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles",
      "link": "https://www.aitrends.com/ai-insider/novelty-in-the-game-of-go-provides-bright-insights-for-ai-and-autonomous-vehicles/",
      "description": "By Lance Eliot, the AI Trends Insider   We already expect that humans to exhibit flashes of brilliance. It might not happen all the time, but the act itself is welcomed and not altogether disturbing when it occurs.    What about when Artificial Intelligence (AI) seems to display an act of novelty? Any such instance is bound to get our attention; [&#8230;]]]>",
      "pubDate": "2021-10-28T21:49:47.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 17,
      "title_zh": "Novelty In The Game Of Go Provides Bright Insights For AI And Autonomous Vehicles"
    },
    {
      "title": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias",
      "link": "https://www.aitrends.com/ai-world-government/promise-and-perils-of-using-ai-for-hiring-guard-against-data-bias/",
      "description": "By AI Trends Staff   While AI in hiring is now widely used for writing job descriptions, screening candidates, and automating interviews, it poses a risk of wide discrimination if not implemented carefully.  That was the message from Keith Sonderling, Commissioner with the US Equal Opportunity Commision, speaking at the AI World Government event held live and virtually in [&#8230;]]]>",
      "pubDate": "2021-10-28T23:18:48.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 16,
      "title_zh": "Promise and Perils of Using AI for Hiring: Guard Against Data Bias"
    },
    {
      "title": "Predictive Maintenance Proving Out as Successful AI Use Case",
      "link": "https://www.aitrends.com/predictive-analytics/predictive-maintenance-proving-out-as-successful-ai-use-case/",
      "description": "By John P. Desmond, AI Trends Editor   More companies are successfully exploiting predictive maintenance systems that combine AI and IoT sensors to collect data that anticipates breakdowns and recommends preventive action before break or machines fail, in a demonstration of an AI use case with proven value.   This growth is reflected in optimistic market forecasts. [&#8230;]]]>",
      "pubDate": "2021-10-28T22:10:19.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 16,
      "title_zh": "Predictive Maintenance Proving Out as Successful AI Use Case"
    },
    {
      "title": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams",
      "link": "https://www.aitrends.com/ai-world-government/digital-natives-seen-having-advantages-as-part-of-government-ai-engineering-teams/",
      "description": "By John P. Desmond, AI Trends Editor   AI is more accessible to young people in the workforce who grew up as ‘digital natives’ with Alexa and self-driving cars as part of the landscape, giving them expectations grounded in their experience of what is possible.   That idea set the foundation for a panel discussion at AI World [&#8230;]]]>",
      "pubDate": "2021-10-21T20:52:34.000Z",
      "source": "AI 趋势",
      "category": "行业趋势",
      "aiScore": 16,
      "title_zh": "Digital Natives Seen Having Advantages as Part of Government AI Engineering Teams"
    },
    {
      "title": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods",
      "link": "https://arxiv.org/abs/2602.07040",
      "description": "arXiv:2602.07040v1 Announce Type: new \nAbstract: We introduce Aster, an AI agent for autonomous scientific discovery capable of operating over 20 times faster than existing frameworks. Given a task, an initial program, and a script to evaluate the performance of the program, Aster iteratively improves the program, often leading to new state-of-the-art performances. Aster's significant reduction in the number of iterations required for novel discovery expands the domain of tractable problems to i",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 12,
      "title_zh": "Aster: Autonomous Scientific Discovery over 20x Faster Than Existing Methods"
    },
    {
      "title": "Is there \"Secret Sauce'' in Large Language Model Development?",
      "link": "https://arxiv.org/abs/2602.07238",
      "description": "arXiv:2602.07238v1 Announce Type: new \nAbstract: Do leading LLM developers possess a proprietary ``secret sauce'', or is LLM performance driven by scaling up compute? Using training and benchmark data for 809 models released between 2022 and 2025, we estimate scaling-law regressions with release-date and developer fixed effects. We find clear evidence of developer-specific efficiency advantages, but their importance depends on where models lie in the performance distribution. At the frontier, 80",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 10,
      "title_zh": "Is there \"Secret Sauce'' in Large Language Model Development?"
    },
    {
      "title": "BRIDGE: Predicting Human Task Completion Time From Model Performance",
      "link": "https://arxiv.org/abs/2602.07267",
      "description": "arXiv:2602.07267v1 Announce Type: new \nAbstract: Evaluating the real-world capabilities of AI systems requires grounding benchmark performance in human-interpretable measures of task difficulty. Existing approaches that rely on direct human task completion time annotations are costly, noisy, and difficult to scale across benchmarks. In this work, we propose BRIDGE, a unified psychometric framework that learns the latent difficulty scale from model responses and anchors it to human task completio",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 4,
      "title_zh": "BRIDGE: Predicting Human Task Completion Time From Model Performance"
    },
    {
      "title": "ST-Raptor: An Agentic System for Semi-Structured Table QA",
      "link": "https://arxiv.org/abs/2602.07034",
      "description": "arXiv:2602.07034v1 Announce Type: new \nAbstract: Semi-structured table question answering (QA) is a challenging task that requires (1) precise extraction of cell contents and positions and (2) accurate recovery of key implicit logical structures, hierarchical relationships, and semantic associations encoded in table layouts. In practice, such tables are often interpreted manually by human experts, which is labor-intensive and time-consuming. However, automating this process remains difficult. Ex",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 3,
      "title_zh": "ST-Raptor: An Agentic System for Semi-Structured Table QA"
    },
    {
      "title": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents",
      "link": "https://arxiv.org/abs/2602.07035",
      "description": "arXiv:2602.07035v1 Announce Type: new \nAbstract: Recently, Diffusion Large Language Models (dLLMs) have demonstrated unique efficiency advantages, enabled by their inherently parallel decoding mechanism and flexible generation paradigm. Meanwhile, despite the rapid advancement of Search Agents, their practical deployment is constrained by a fundamental limitation, termed as 1) Latency Challenge: the serial execution of multi-round reasoning, tool calling, and tool response waiting under the ReAc",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 3,
      "title_zh": "DLLM-Searcher: Adapting Diffusion Large Language Model for Search Agents"
    },
    {
      "title": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View",
      "link": "https://arxiv.org/abs/2602.07253",
      "description": "arXiv:2602.07253v1 Announce Type: new \nAbstract: Detecting hallucinations in large language models is a critical open problem with significant implications for safety and reliability. While existing hallucination detection methods achieve strong performance in question-answering tasks, they remain less effective on tasks requiring reasoning. In this work, we revisit hallucination detection through the lens of out-of-distribution (OOD) detection, a well-studied problem in areas like computer visi",
      "pubDate": "2026-02-10T05:00:00.000Z",
      "source": "ArXiv AI 研究",
      "category": "学术研究",
      "aiScore": 3,
      "title_zh": "From Out-of-Distribution Detection to Hallucination Detection: A Geometric View"
    }
  ],
  "metadata": {
    "totalCount": 16,
    "generatedAt": "2026-02-10T16:52:02.516Z",
    "sources": [
      {
        "name": "ArXiv AI 研究",
        "category": "学术研究",
        "weight": 0.9
      },
      {
        "name": "MIT人工智能新闻",
        "category": "学术动态",
        "weight": 0.85
      },
      {
        "name": "AI 趋势",
        "category": "行业趋势",
        "weight": 0.8
      },
      {
        "name": "VentureBeat AI",
        "category": "商业资讯",
        "weight": 0.8
      }
    ],
    "keywords": {
      "tier1": {
        "artificial intelligence": 5,
        "AI": 4,
        "machine learning": 4,
        "deep learning": 4,
        "neural network": 3,
        "neural networks": 3,
        "LLM": 3,
        "GPT": 3,
        "ChatGPT": 3,
        "computer vision": 3,
        "natural language processing": 3,
        "NLP": 3,
        "robotics": 2.5,
        "automation": 2.5,
        "algorithm": 2
      },
      "tier2": {
        "transformer": 2,
        "bert": 2,
        "dall-e": 2,
        "stable diffusion": 2,
        "reinforcement learning": 2,
        "supervised learning": 2,
        "unsupervised learning": 2,
        "data science": 1.5,
        "big data": 1.5,
        "cloud computing": 1,
        "edge computing": 1
      }
    }
  },
  "summary": {
    "researchArticles": 8,
    "industryArticles": 8,
    "academicArticles": 8,
    "averageScore": 14.875
  }
}